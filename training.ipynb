{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4295f72",
   "metadata": {},
   "source": [
    "# Kepler Mission model training\n",
    "This section of the notebook trains a neural network based on the contents of the cumulative Kepler exoplanets table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e21cb6",
   "metadata": {},
   "source": [
    "## Dependencies import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pathlib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e678ca1",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = pathlib.Path('datasets_xg')\n",
    "\n",
    "X_acc, Y_acc = [], []\n",
    "\n",
    "for file in directory.iterdir():\n",
    "    df = pd.read_csv(file)\n",
    "    to_drop_old = ['id', 'goals_period2', 'opposition_goals_period2', 'ballPossession_period2', 'opposition_ballPossession_period2', 'bigChanceCreated_period2', 'opposition_bigChanceCreated_period2', 'totalShotsOnGoal_period2', 'opposition_totalShotsOnGoal_period2', 'goalkeeperSaves_period2', 'opposition_goalkeeperSaves_period2', 'cornerKicks_period2', 'opposition_cornerKicks_period2', 'passes_period2', 'opposition_passes_period2', 'totalTackle_period2', 'opposition_totalTackle_period2', 'freeKicks_period2', 'opposition_freeKicks_period2', 'shotsOnGoal_period2', 'opposition_shotsOnGoal_period2', 'hitWoodwork_period2', 'opposition_hitWoodwork_period2', 'shotsOffGoal_period2', 'opposition_shotsOffGoal_period2', 'blockedScoringAttempt_period2', 'opposition_blockedScoringAttempt_period2', 'totalShotsInsideBox_period2', 'opposition_totalShotsInsideBox_period2', 'totalShotsOutsideBox_period2', 'opposition_totalShotsOutsideBox_period2', 'offsides_period2', 'opposition_offsides_period2', 'accuratePasses_period2', 'opposition_accuratePasses_period2', 'throwIns_period2', 'opposition_throwIns_period2', 'finalThirdEntries_period2', 'opposition_finalThirdEntries_period2', 'accurateLongBalls_period2', 'opposition_accurateLongBalls_period2', 'accurateCross_period2', 'opposition_accurateCross_period2', 'duelWonPercent_period2', 'opposition_duelWonPercent_period2', 'dispossessed_period2', 'opposition_dispossessed_period2', 'groundDuelsPercentage_period2', 'opposition_groundDuelsPercentage_period2', 'aerialDuelsPercentage_period2', 'opposition_aerialDuelsPercentage_period2', 'dribblesPercentage_period2', 'opposition_dribblesPercentage_period2', 'wonTacklePercent_period2', 'opposition_wonTacklePercent_period2', 'interceptionWon_period2', 'opposition_interceptionWon_period2', 'totalClearance_period2', 'opposition_totalClearance_period2', 'goalKicks_period2', 'opposition_goalKicks_period2']\n",
    "    df = df.drop(columns=['id']).reset_index(drop=True)\n",
    "    df = df.iloc[::-1].reset_index(drop=True)\n",
    "    result_counts = df['result'].value_counts()\n",
    "    min = result_counts.min()\n",
    "\n",
    "    for value, count in result_counts.items():\n",
    "        to_trim = count - min\n",
    "        if to_trim > 0:\n",
    "            idx = df[df[\"result\"] == value].sample(n=to_trim, random_state=42).index\n",
    "            df = df.drop(idx)\n",
    "\n",
    "    Y = df['result']\n",
    "    X = df.drop(columns=['result']).values.astype(np.float32)\n",
    "\n",
    "    X_acc.extend(X)\n",
    "    Y_acc.extend(Y)\n",
    "\n",
    "X_acc = np.array(X_acc, dtype=np.float32)\n",
    "Y_acc = np.array(Y_acc)\n",
    "\n",
    "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(\n",
    "    X_acc,\n",
    "    Y_acc,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y_acc\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_unscaled)\n",
    "X_test_scaled = scaler.transform(X_test_unscaled)\n",
    "\n",
    "pca = PCA(n_components=0.95)  # keep 95% variance\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "X_train = X_train_pca\n",
    "X_test = X_test_pca\n",
    "\n",
    "joblib.dump(scaler, \"kepler_scaler.pkl\")\n",
    "joblib.dump(pca, \"kepler_pca.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=500,     # number of trees\n",
    "    max_depth=None,      # let trees grow fully\n",
    "    min_samples_leaf=2, # helps generalization\n",
    "    n_jobs=-1,          # use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_unscaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_unscaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d190fe1",
   "metadata": {},
   "source": [
    "## Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_compile_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(X_train.shape[1],))\n",
    "norm = layers.BatchNormalization()(input_layer)\n",
    "\n",
    "x = layers.Dense(128, activation=\"relu\")(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(32, activation=\"relu\")(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Concatenate()([x, norm])\n",
    "\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "output = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c6b38",
   "metadata": {},
   "source": [
    "## Training callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early_stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6894bffe",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=1000,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kepler.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8f9f8",
   "metadata": {},
   "source": [
    "## Testing and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['HOME', 'AWAY', 'DRAW']\n",
    "\n",
    "Y_pred_probs = model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred_probs, axis=1)\n",
    "\n",
    "Y_pred_strings = [labels[i] for i in Y_pred]\n",
    "Y_true_strings = [labels[i] for i in y_test]\n",
    "\n",
    "cm = confusion_matrix(Y_true_strings, Y_pred_strings, labels=labels)\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    Y_pred,\n",
    "    labels=[0,1,2],\n",
    "    target_names=labels\n",
    "))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
